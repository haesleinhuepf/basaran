{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ed4cfd-e2d8-4884-9e50-cc28e9d30db9",
   "metadata": {},
   "source": [
    "# Setting up a local LLM server\n",
    "In this notebook, we will use [basaran](https://github.com/hyperonym/basaran) as a local LLM server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2fd8f-51f5-4df9-b568-df8548087c8a",
   "metadata": {},
   "source": [
    "## Code download and installation\n",
    "Clone the `windows_modern_openai` branch from https://github.com/haesleinhuepf/basaran . Navigate to the folder and run `pip install -e .` from there.\n",
    "Also execute `pip install openai==1.5.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a9e59-13d7-4848-a128-22bfd2cfb308",
   "metadata": {},
   "source": [
    "## Model download\n",
    "To have a model to play with, we need to download a small one, e.g. [TinyLlama](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0).\n",
    "We can use this code which will cache the model in the huggingface .cache folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955ecce6-60f3-436a-ad79-77725e9bf88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a friendly chatbot who always responds in the style of a pirate</s>\n",
      "<|user|>\n",
      "How many helicopters can a human eat in one sitting?</s>\n",
      "<|assistant|>\n",
      "As humans, we can eat a reasonable amount of food in one sitting, depending on our body weight and appetite. However, eating too much food at once can lead to stomach cramps, bloating, and other digestive issues. A reasonable amount for a human to eat in one sitting would be 4-5 servings, which is about 4-5 cups of food.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea7952-ece1-4334-9714-782557bc7afb",
   "metadata": {},
   "source": [
    "## Starting the server\n",
    "Replace `haase` in the following command with your username. Also check if the snapshot may have a different name. Then run this from the terminal (in a separate window):\n",
    "\n",
    "```\n",
    "SET MODEL=C:\\Users\\haase\\.cache\\huggingface\\hub\\models--TinyLlama--TinyLlama-1.1B-Chat-v1.0\\snapshots\\77e23968eed12d195bd46c519aa679cc22a27ddc&& set PORT=80 && python -m basaran\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d2cba7-6d89-4918-9286-326dd8dadd42",
   "metadata": {},
   "source": [
    "The server should say something like \n",
    "```\n",
    "start listening on 127.0.0.1:80\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc2e69-0d05-4429-9352-2efbd28b30b4",
   "metadata": {},
   "source": [
    "## Testing the server\n",
    "You can test the server using curl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655d00cc-74ed-4a8b-8ada-4e9d5ef5cc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"cmpl-b0954aecfa6b351b807baa2b\",\"object\":\"text_completion\",\"created\":1705783287,\"model\":\"C:\\\\Users\\\\haase\\\\.cache\\\\huggingface\\\\hub\\\\models--TinyLlama--TinyLlama-1.1B-Chat-v1.0\\\\snapshots\\\\77e23968eed12d195bd46c519aa679cc22a27ddc\",\"choices\":[{\"text\":\"<|system|>\\n\",\"index\":0,\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":1,\"completion_tokens\":7,\"total_tokens\":8}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100     2    0     0  100     2      0      1  0:00:02  0:00:01  0:00:01     1\n",
      "100     2    0     0    0     2      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "100     2    0     0    0     2      0      0 --:--:--  0:00:03 --:--:--     0\n",
      "100     2    0     0    0     2      0      0 --:--:--  0:00:04 --:--:--     0\n",
      "100   392  100   390    0     2     80      0  0:00:04  0:00:04 --:--:--    81\n",
      "100   392  100   390    0     2     80      0  0:00:04  0:00:04 --:--:--   102\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: application\n",
      "curl: (3) URL rejected: Port number was not a decimal number between 0 and 65535\n",
      "curl: (3) URL rejected: Malformed input to a URL function\n",
      "curl: (3) URL rejected: Port number was not a decimal number between 0 and 65535\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: true\n",
      "curl: (3) unmatched close brace/bracket in URL position 1:\n",
      "}'\n",
      " ^\n"
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1/v1/completions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -d '{ \"prompt\": \"once upon a time,\", \"echo\": true }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e093a8c-c8d1-4d88-aec1-7f1bc0002e23",
   "metadata": {},
   "source": [
    "## Accessing the LLM using openai's API\n",
    "Next, we will use the openai python API to access our local LLM server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b29c237-e5dc-4790-b66a-22dc87bc0143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3992fe9-e784-4d96-9bf3-f2e482d12e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "client.base_url = 'http://127.0.0.1/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b989e8d-a5af-40fe-a698-8c064613e693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " meet the animals.\n",
      "\n",
      "Act 2\n",
      "As Max and Moritz are exploring the forest, Max meets a rabbit that needs help to escape a pack of wolves. Max goes to the forest's owner to help; and a tie to the owner appears in the form of a book. Max reads the story and learns the right way to help the rabbit to escape.\n",
      "\n",
      "Act 3\n",
      "Max and Moritz are heading back to their village when, in an attempt to pass an obstacle, they accidentally take a long shortcut through a vibrant meadow. When they arrive, they find that an entire family has been wiped out because they all thought Max was going to eat them! Max and Moritz use their friendship to sweet-talk the family, and they make peace with them.\n",
      "\n",
      "Epilogue\n",
      "A happy ending ensues where Max and Moritz are reunited, and the forest seems peaceful once again\n"
     ]
    }
   ],
   "source": [
    "response = client.completions.create(\n",
    "    model=\"xyz\",\n",
    "    prompt=\"Max and Moritz go in the forest to\",\n",
    "    max_tokens=200\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2fe47-086b-40e8-ad33-3f5710570b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
